Хабр Geektimes Тостер Мой круг Фрилансим Публикации Пользователи Хабы Компании Песочница Войти Регистрация ITSumma 236,00 Собираем безумных людей и вместе спасаем интернет aghast сегодня в 08:18 Как мы сайт Republic на Kubernetes переводили Блог компании ITSumma, Kubernetes, Высокая производительность, Разработка веб-сайтов, Управление медиа Скандальные, важные и просто очень крутые материалы выходят в СМИ не каждый день, да и со 100% точностью спрогнозировать успешность той или иной статьи не возьмётся ни один редактор. Максимум, чем располагает коллектив — на уровне чутья сказать, «крепкий» материал или же «обычный». Все. Дальше начинается непредсказуемая магия СМИ, благодаря которой статья может выйти в топы поисковой выдачи с десятками ссылок от других изданий или же материал канет в Лету. И вот как раз в случае публикации крутых статей сайты СМИ периодически падают под чудовищным наплывом пользователей, который мы с вами скромно называем «хабраэффектом». Этим летом жертвой профессионализма собственных авторов стал сайт издания Republic: статьи на тему пенсионной реформы, о школьном образовании и правильном питании в общей сложности собрали аудиторию в несколько миллионов читателей. Публикация каждого упомянутого материала приводила к настолько высоким нагрузкам, что до падения сайта Republic оставалось совсем «вот столечко». Администрация осознала, что надо что-то менять: нужно было изменить структуру проекта таким образом, чтобы он мог живо реагировать на изменение условий работы (в основном, внешней нагрузки), оставаясь полностью работоспособным и доступным для читателей даже в моменты очень резких скачков посещаемости. И отличным бонусом было бы минимальное ручное вмешательство технической команды Republic в такие моменты. По итогам совместного со специалистами Republic обсуждения различных вариантов реализации озвученных хотелок мы решили перевести сайт издания на Kubernetes*. О том, чего нам всем это стоило, и будет наш сегодняшний рассказ. *В ходе переезда ни один технический специалист Republic не пострадал Как это выглядело в общих чертах Началось всё, само собой, с переговоров, как всё будет происходить «сейчас» и «потом». К сожалению, современная парадигма на IT-рынке подразумевает, что как только какая-либо компания отправляется на сторону за каким-то инфраструктурным решением, то ей подсовывают прейскурант услуг «под ключ». Казалось бы, работы «под ключ» — что может быть приятнее и милее условному директору или владельцу бизнеса? Заплатил, и голова не болит: планирование, разработка, поддержка — все находится там, на стороне подрядчика, бизнесу же остаётся лишь зарабатывать деньги на оплату столь приятного сервиса. Однако полная передача IT-инфраструктуры не во всех случаях целесообразна для заказчика в долгосрочной перспективе. Правильнее со всех точек зрения работать одной большой командой, чтобы после завершения проекта клиент понимал, как жить с новой инфраструктурой дальше, а у коллег по цеху со стороны заказчика не было вопроса «ой, а что это тут наворотили?» после подписания акта выполненных работ и демонстрации результатов. Того же мнения придерживались и парни из Republic. В итоге мы на два месяца высадили десант из четырёх человек к клиенту, которые не только реализовали нашу задумку, но и технически подготовили специалистов на стороне Republic к последующей работе и существованию в реалиях Kubernetes. И выиграли от этого все стороны: мы быстро выполнили работу, сохранили своих специалистов готовыми к новым свершениям и получили Republic в качестве клиента на консультативной поддержке с собственными инженерами. Издание же получило новую инфраструктуру, приспособленную к «хабраэффектам», собственный сохранённый штат технических специалистов и возможность обратиться за помощью, если она потребуется. Готовим плацдарм «Разрушать — не строить». Поговорка эта применима вообще к чему угодно. Конечно, наиболее простым решением кажутся упоминаемый ранее захват инфраструктуры клиента в заложники и приковывание его, клиента, к себе цепью, ну или разгон имеющегося штата и требование нанять гуру в новых технологиях. Мы пошли третьим, не самым популярным нынче путём, и начали с обучения инженеров Republic. Примерно такое решение по обеспечению работы сайта мы увидели на старте: То есть, у Republic было просто два железных сервера — основной и дублирующий, резервный. Самым важным для нас было добиться смены парадигмы мышления технических специалистов клиента, потому что ранее они имели дело с весьма простой связкой из NGINX, PHP-fpm и PostgreSQL. Теперь же им предстояло столкнуться с масштабируемой контейнерной архитектурой Kubernetes. Так что вначале мы перевели локальную разработку Republic на docker-compose окружение. И это был только первый шаг. До высадки нашего десанта разработчики Republic держали свое локальное рабочее окружение в виртуальных машинах, конфигурируемых через Vagrant, либо же работали напрямую с dev-сервером по sftp. Исходя из общего базового образа виртуальной машины, каждый разработчик «доконфигурировал» свою машинку «под себя», что порождало целый набор различных конфигураций. Как следствие подобного подхода, подключение в команду новых людей экспоненциально увеличивало время их входа в проект. В новых реалиях мы предложили команде более прозрачную структуру рабочего окружения. В ней декларативно описали, какое ПО и каких версий нужно для проекта, порядок связей и взаимодействия между сервисами (приложениями). Это описание залили в отдельный git-репозиторий, чтобы им можно было удобно централизованно управлять. Все нужные приложения стали запускаться в отдельных docker-контейнерах — а это обычный php-сайт с nginx, много статики, сервисы для работы с изображениями (ресайз, оптимизация и т д), и… отдельный сервис для веб-сокетов, написанный на языке D. Все файлы конфигураций (nginx-conf, php-conf…) тоже стали частью кодовой базы проекта. Соответственно, было «воссоздано» и локальное окружение, полностью идентичное текущей серверной инфраструктуре. Таким образом была снижены времязатраты на поддержание одинакового окружения как на локальных машинах разработчиков, так и на проде. Что, в свою очередь, сильно помогало избегать совершенно ненужных проблем, вызываемых самописными локальными кофигурациями каждого разработчика. В результате в docker-compose среде были подняты следующие сервисы: web для работы php-fpm приложения; nginx; impproxy и cairosvg (сервисы для работы с изображениями); postgres; redis; elastic-search; trumpet (тот самый сервис для web-сокетов на D). С точки зрения разработчиков работа с кодовой базой осталась неизменной — в нужные сервисы она монтировалась из отдельной директории (базовый репозиторий с кодом сайта) в нужные сервисы: public-директория в nginx-сервис, весь код php-приложения в php-fpm-сервис. Из отдельной директории (в которой содержатся все конфиги compose-окружения) в nginx- и php-fpm- сервисы монтируются соответствующие файлы конфигураций. Директории с данными postgres, elasticsearch и redis также монтируются на локальную машину разработчика, чтобы в случае, если все контейнеры придётся пересобрать/удалить, данные в этих сервисах не были потеряны. Для работы с логами приложений — также в docker-compose окружении — были подняты сервисы ELK-стека. Раньше часть логов приложений писались в стандартные /var/log/…, логи и эксепшены php-приложений писались в Sentry, и такой вариант «децентрализованного» хранения журналов был крайне неудобен в работе. Теперь же приложения и сервисы были сконфигурированы и доработаны для взаимодействия с ELK-стеком. Оперировать логами стало гораздо проще, у разработчиков появился удобный интерфейс для поиска, фильтрации логов. В дальнейшем (уже в кубике) — можно смотреть логи конкретной версии приложения (например, кронжобы, запущенной позавчера). Далее у команды Republic начался небольшой период адаптации. Команде нужно было понять и научиться работать в условиях новой парадигмы разработки, в которой необходимо учитывать следующее: Приложения становятся stateless, и у них в любой момент могут пропасть данные, поэтому работа с базами данных, сессиями, статичными файлами должна быть построена иначе. PHP-сессии должны храниться централизованно и шариться между всеми инстансами приложения. Это могут продолжать быть файлы, но чаще для этих целей берут redis из-за большего удобства управления. Контейнеры для баз данных должны либо «монтировать в себя» датадиру, либо БД должна быть запущена вне контейнерной инфраструктуры. Файловое хранилище из порядка 50-60 Гб картинок не должно находиться «внутри веб-приложения». Для таких целей необходимо использовать какое-либо внешнее хранилище, cdn-системы и т.д. Все приложения (базы данных, аппликейшен-серверы…) теперь являются отдельными «сервисами», и взаимодействие между ними должно конфигурироваться относительно нового пространства имен. После того, как команда разработки Republic освоилась с нововведениями, мы начали перевод продовой инфраструктуры издания на Kubernetes. А вот и Kubernetes На основе построенного для локальной разработки docker-compose окружения мы начали переводить проект в «кубик». Все сервисы, на которых проект построен локально, мы «запаковали в контейнеры»: организовали линейную и понятную процедуру сборки приложений, хранения конфигураций, компилирования статики. С точки зрения разработки — вынесли нужные нам параметры конфигураций в переменные окружения, стали хранить сессии не в файлах, а в редисе. Подняли тестовую среду, где развернули работоспособную версию сайта. Так как это бывший монолитный проект, очевидно, что имела место быть жёсткая зависимость между версиями фронтенда и бекенда — соответственно, и деплоились эти два компонента одновременно. Поэтому поды web-приложения мы решили построить таким образом, чтобы в одном поде крутилось сразу два контейнера: php-fpm и nginx. Мы построили также автоскейлинг, чтобы web-приложения масштабировались максимум до 12 в пике трафика, поставили определённые liveness/readiness пробы, потому что приложение требует как минимум 2 минуты на запуск (поскольку нужно прогреть кэш, сгенерировать конфиги…) Тут же, конечно, нашлись всякие косяки и нюансы. Например: скомпиленная статика была необходима как web-серверу, который её раздавал, так и application-серверу на fpm’е, который где-то на лету генерировал какие-то картинки, где-то прямо кодом отдавал svg. Мы поняли: чтобы два раза не вставать, нужно создать промежуточный build-контейнер и финальную сборку контейнеризировать через multi-stage. Для этого мы создали несколько промежуточных контейнеров, в каждом из которых зависимости подтягиваются отдельно, потом отдельно собирается статика (css и js), и после в два контейнера — в nginx и в fpm— они копируются из промежуточного build-контейнера. Стартуем Для работы с файлами первой итерацией мы сделали общую директорию, которая синхронизировалась на все рабочие машины. Под словом «синхронизировалась» я тут подразумеваю именно то, о чём с ужасом можно подумать в первую очередь — rsync по кругу. Очевидно неудачное решение. В итоге всё дисковое пространство мы завели на GlusterFS, настроили работу с картинками так, что они всегда были доступны с любой машины и ничего не тормозило. Для взаимодействия наших приложений с системами хранения данных (postgres, elasticsearch, redis) в k8s были созданы ExternalName-сервисы, чтобы в случае, например, срочного переключения на резервную базу данных обновить параметры подключения в одном месте. Всю работу с cron’ами вынесли в новые сущности k8s — cronjob, которые умеют запускаться по определённому расписанию. В итоге мы получили такую архитектуру: Кликабельно О трудном Это был запуск первой версии, потому что параллельно с полным перестроением инфраструктуры сайт ещё проходил редизайн. Часть сайта собиралась с одними параметрами — для статики и всего остального, а часть — с другими. Там приходилось… как бы помягче сказать… извращаться со всеми этими multistage-контейнерами, копировать данные из них в разном порядке и т.д. Также нам пришлось потанцевать с бубнами вокруг CI\CD системы, чтобы научить всё это деплоить и контроллить с разных репозиториев и из разных окружений. Ведь нужен постоянный контроль над версиями приложений, чтобы можно было понять, когда произошёл деплой того или иного сервиса и с какой версии приложения начались те или иные ошибки. Для этого мы наладили правильную систему логирования (а также саму культуру ведения логов) и внедрили ELK. Коллеги научились ставить определённые селекторы, смотреть, какой cron генерирует какие ошибки, как он вообще выполняется, ведь в «кубике» после того, как cron-контейнер выполнился, ты в него больше не попадёшь. Но самым сложным для нас было переработать и пересмотреть всю кодовую базу. Напомню, Republic — это проект, которому нынче исполняется 10 лет. Начинался он одной командой, сейчас развивается другой, и перелопатить все-все исходники на предмет возможных багов и ошибок реально сложно. Конечно, в этот момент наш десант из четырех человек подключил ресурсы остальной команды: мы прокликивали и прогоняли тестами весь сайт, даже в тех разделах, которые живые люди не посещали с 2016 года. Без фейлов никуда В понедельник, ранним утром, когда людям пошла массовая рассылка с дайджестом, у нас всё встало колом. Виновник нашёлся довольно быстро: запустился cronjob и начал люто-бешено слать письма всем желающим получить подборку новостей за прошедшую неделю, сожрав попутно ресурсы всего кластера. С подобным поведением мы смириться не могли, так что мы быстро проставили жёсткие лимиты на все ресурсы: сколько процессора и памяти может жрать потреблять контейнер и так далее. Как справлялась команда девелоперов Republic Изменений наша деятельность принесла немало, и мы это понимали. По сути, мы не только перекроили инфраструктуру издания, вместо привычной связки «основной-резервный сервер» внедрив контейнерное решение, которое по мере необходимости подключает дополнительные ресурсы, но и полностью изменили подход к дальнейшей разработке. Спустя некоторое время ребята начали понимать, что это не напрямую работа с кодом, а работа с абстрактным приложением. Учитывая процессы CI\CD (построенные на Jenkins), они начали писать тесты, у них появились полноценные dev-stage-prod-окружения, где они могут в реальном времени тестировать новые версии своего приложения, смотреть, где что отваливается, и учиться жить в новом идеальном мире. Что получил клиент Прежде всего, Republic наконец-то получил контролируемый процесс деплоя! Раньше как происходило: в Republic был ответственный человек, который шёл на сервер, запускал всё вручную, затем собирал статику, проверял руками, что ничего не отвалилось… Сейчас процесс деплоя выстроен так, что разработчики занимаются именно разработкой и не тратят время ни на что другое. Да и у ответственного теперь одна задача — следить за тем, как прошёл релиз в общем. После того, как происходит пуш в мастер-ветку, либо автоматически, либо деплоем «по кнопке» (периодически из-за определенных бизнесовых требований автоматический деплой отключается), в бой вступает Jenkins: начинается сборка проекта. Первым делом собираются все docker-контейнеры: в подготовительных контейнерах устанавливаются зависимости (composer, yarn, npm), что позволяет ускорить процесс сборки, если при деплое список необходимых библиотек не изменился; затем собираются контейнеры для php-fpm, nginx, остальных сервисов, в которые, по аналогии с docker-compose окружением, копируются только нужные части кодовой базы. После этого запускаются тесты и, в случае успешного прохождения тестов, происходит пуш образов в приватное хранилище и, собственно, раскатка деплойментов в кубере. Благодаря переводу Republic на k8s мы получили архитектуру, использующую кластер из трёх реальных машин, на которых может одновременно «крутиться» до двенадцати копий веб-приложения. При этом система сама, исходя из текущих нагрузок, решает, сколько копий ей нужно прямо сейчас. Мы увели Republic от лотереи «работает – не работает» со статичными основным и резервным сервером и построили для них гибкую систему, готовую к лавинообразному росту нагрузки на сайт. В этот момент может возникнуть вопрос «ребята, вы сменили две железки на те же железки, но с виртуализацией, какой выигрыш, вы там вообще в порядке?» И, конечно, он будет закономерен. Но лишь отчасти. По итогу мы получили не просто железки с виртуализацией. Мы получили стабилизированное рабочее окружение, одинаковое как в проде, так и на деве. Окружение, которое управляется централизованно для всех участников проекта. Мы получили механизм сборки всего проекта и выкатки релизов, опять же, единый для всех. Мы получили удобную систему оркестрации проекта. Как только команда Republic заметит, что им в целом перестаёт хватать текущих ресурсов и риски сверхвысоких нагрузок (либо когда уже стряслось и всё легло), они просто берут ещё один сервер, за 10 минут раскатывают на нём роль узла кластера, и оп-оп — всё снова красиво и хорошо. Предыдущая же структура проекта вообще не предполагала такого подхода, там не было ни медленных, ни быстрых решений подобных проблем. Во-вторых, появился бесшовный деплой: посетитель либо попадёт на старую версию приложения, либо на новую. А не как раньше, когда контент мог быть новый, а стили старые. В итоге, бизнес доволен: всякие новые вещи теперь можно делать быстрее и чаще. Суммарно от «а давайте попробуем» до «готово» работа над проектом заняла 2 месяца. Команда с нашей стороны — героический десант в четыре человека + поддержка «базы» на время проверки кода и тестов. Что получили пользователи А посетители, в принципе, изменений не увидели. Процесс деплоя на стратегии RollingUpdate построен «бесшовным». Выкатывание новой версии сайта НИКАК не задевает пользователей, новая версия сайта, пока не пройдут тесты и liveness/readiness пробы, не будет доступна. Они просто видят, что сайт работает и вроде не собирается падать после публикации крутых статей. Что, в общем-то, и нужно любому проекту. Теги: kubernetes highload ITSumma медиа сми Добавить метки Пометьте публикацию своими метками Метки лучше разделять запятой. Например: программирование, алгоритмы Сохранить +36 37 3k 27 Нарушение Опишите суть нарушения Отправить Выберите рекомендации для отправки автору: Указан только блог Орфографические ошибки Пунктуационные ошибки Отступы Текст-простыня Короткие предложения Смайлики Много форматирования Картинки Ссылки Оформление кода Рекламный характер Отправить ITSumma 236,00 Собираем безумных людей и вместе спасаем интернет 15,0 Карма 28,8 Рейтинг 2 Подписчики AndreyS aghast краб Сайт Facebook Twitter ВКонтакте Github Поделиться публикацией Похожие публикации 2 января 2018 в 21:06 Докер мертв +70 80,1k 119 282 Комментарии 27 ProFfeSsoRr сегодня в 09:02 0 сожрав попутно ресурсы всего кластера Т.е. ваш десант профессионалов до работы с Republic не знал, что надо лимиты проставлять? 4umak сегодня в 09:14 +3 Для этого и есть раздел «фейлы»:) Конечно знал, как же иначе. Но от кронджобов на тот момент не ожидали такой прыти:) Всё было заранее омониторено, так что никто особо не пострадал. LuckySB сегодня в 13:12 +1 с кронджобами еще немало граблей есть. посмотрите и помедитируйте над .spec.startingDeadlineSeconds .spec.concurrencyPolicy .spec.successfulJobsHistoryLimit .spec.failedJobsHistoryLimit gecube сегодня в 10:10 +2 Меня интересует то, что осталось за кадром. Куб поверх bare metal? Как подам назначают ip? Или есть overlay сеть? Безопасность: докеры с рутом внутри? Egress/ingress/podpolicy/namespaces? Что с pvc? Хранилище? Это на тех же нодах? А добавлять тогда ещё ноду? Хранилище ведь тоже придется растягивать, иначе привет локальность данных? Как сделан LB снаружи? Понятно, что если облако, то все круто. А если куб на баре метал (ведь именно так?)? Vrrp? Балансировка по Dns? Почему не взяли openshift? В нем очень удобно строить пайплайны через встроенный Дженкинс. Ну, и получаете все возможности куба, если нужно. Как я понял, проект пока не дорос до Истио и сквозного трейсинга запросов (jaeger, например) — нету? 4umak сегодня в 11:03 +2 Куб поверх bare metal? ага Как подам назначают ip? Или есть overlay сеть? сеть на Calico Безопасность: докеры с рутом внутри? Egress/ingress/podpolicy/namespaces? сколько всего в одном вопросе собрали) Egress нет, Ingress да, podPolicy нет, неймспейсы да. Внутри контейнеров есть вещи, крутящиеся от рута, да. Что с pvc? Хранилище? Это на тех же нодах? А добавлять тогда ещё ноду? Хранилище ведь тоже придется растягивать, иначе привет локальность данных? Хранилище на гластере, пока на тех же нодах, да. Придётся, что поделать:) Возможно, в будущем придём к другому варианту с хранилкой. Как сделан LB снаружи? Понятно, что если облако, то все круто. А если куб на баре метал (ведь именно так?)? Vrrp? Балансировка по Dns? DNS, да Почему не взяли openshift? В нем очень удобно строить пайплайны через встроенный Дженкинс. Ну, и получаете все возможности куба, если нужно. С кубом больше опыта, банально. Ну а пайплайнами из дженкинса, в целом, без разницы, куда тыкать:) Как я понял, проект пока не дорос до Истио и сквозного трейсинга запросов (jaeger, например) — нету? Не, не было пока нужды, правильно понимаете gecube сегодня в 12:04 +1 По LB и DNS интересно подробнее. Смотрите. Речь идёт про веб-сайт, конечными пользователями… являются юзеры (простите, за тавтологию). Не мобильное приложение, десктопное приложение и пр., а именно, что живые люди. Живым людям надо отдать DNS. Единый адрес сайта, независимо от того, какая из год живёт. А здесь могут быть варианты. Либо мы назначаем А запись на некий фиксированный плавающий ip между нодами (vrrp?). Либо нам нужно оперативно править DNS. Либо у нас есть свой LB перед озвученными нодами, но он тогда становится сам точкой отказа. В общем — прошу больше подробностей, вряд ли эта реализация является коммерческой тайной и ноу-хау. Второй момент. Сейчас две ноды в кубе. Положим, получается история, что они друг друга не видят. И обе думают, что единственные живые ноды. Как планируете решать? Тем более, что, как я понимаю, новостной сайт подразумевает какое-то состояние, которое должно разделяться (реплицироваться) между нодами — зарегистрированные пользователя, комментарии к статьям и пр. Или этого всего нет и сервис ТОЛЬКО и делает, что отдает предварительно подготовленный контент ? И что тогда с CDN, чтобы побыстрее статику отдавать клиентам? Нет его? 4umak сегодня в 12:25 +2 Либо нам нужно оперативно править DNS Именно так, балансировка исключительно днсами в данный момент выполняется. Сейчас две ноды в кубе. опс, вот тут у нас информационная диверсия вышла, нод не две, а три. Как на схеме нарисовано. В тексте сейчас поправим. Тем более, что, как я понимаю, новостной сайт подразумевает какое-то состояние, которое должно разделяться (реплицироваться) между нодами состояние в БД, которая подключена внешним сервисом, что тоже отмечено на схеме. И что тогда с CDN, чтобы побыстрее статику отдавать клиентам? Нет его? нет, в данный момент CDN не используется. Но в целом, при выкатке нового релиза ничего не мешает статике так же компилить и заливать в CDN, в целом. onegreyonewhite сегодня в 12:40 0 Получается DB является «бутылочным горлышком» системы? Если не секрет, как планируете решать? Или считается, что DB никогда не упадёт/перенагрузится? 4umak сегодня в 13:03 0 Даа, пока основным камнем преткновения, если что, будет база. Не секрет, прямо сейчас никак не планируем решать, запас мощности сильно достаточный, есть резервирование. Но в целом да, это будет ещё отдельная головная боль. maxim_ge сегодня в 13:54 +1 >А здесь могут быть варианты. Либо мы назначаем А запись на некий фиксированный плавающий ip между нодами (vrrp?). Можно сделать две-три А-записи для нескольких IP, по крайней мере, браузеры понимают, что если один IP-адрес недоступен, нужно пойти на второй (или на третий). nslookup также показывает все адреса. gecube сегодня в 14:45 0 Понимать-то понимают, но запрос уже может быть потерян. Т.е. условно у Вас пул из 5 IP и вы создаете 5 A записей на них. Один хост падает. Итог — в среднем теряется 1/5 всех запросов. Безвозвратно. В случае, если клиент приложение, а не браузер клиента — ок, можем сделать ретрай. А если нет? maxim_ge сегодня в 15:34 0 А если хост падает, разве можно как-то «сохранить» уже отправленный ему по http(s) запрос? gecube сегодня в 15:45 0 Отправленный — нет, конечно. Но речь про то, чтобы последующие запросы попадали в правильные места. «Правильные» http-клиенты тупо при нескольких A записях шлют запросы по раунд-робину. И я уж не говорю про те случаи, когда пользователь сидит дома за роутером и вопрос — сколько уровней кэша у его ДНСа? Это я к «править ДНС вручную при отказе узла» (даже если TTL маленький). maxim_ge сегодня в 16:26 0 Мы делали эксперимент на swarm с тремя нодами, traefik в качестве reverse proxy. Одну ноду останавливаем, после этого один раз chrome (который браузер) кашляет (не всегда), далее работает нормально. onegreyonewhite сегодня в 12:04 +1 А чем куб разворачиваете? Kubspray'ем? gecube сегодня в 12:07 +2 Да, ещё отдельный вопрос. Наличие куба отчасти заменяет необходимость тащить scm для управления целевыми серверами. Ну, тем более scm на два сервера — оверкилл, проще ансиблом тогда описать среду ) Но вот сам куб предполагает подготовку ноды. А у вас там ещё гластер, БД и прочее. Что нужно для начала бутстрвппить, а потом поддерживать. Вот и интересно, что сделано для этого. 4umak сегодня в 13:56 0 Для куба у нас есть пучок готовых плейбуков ансибловых, поэтому докидывать новые выч.мощности можно очень быстро. БД отдельным внешним сервисом сделана, про неё в ветке выше отметил. Гластер пока руками, если что, менеджерить придётся, да. maxim_ge сегодня в 12:35 0 Благодаря переводу Republic на k8s мы получили архитектуру, использующую кластер из трёх реальных машин, на которых может одновременно «крутиться» до двенадцати копий веб-приложения. При этом система сама, исходя из текущих нагрузок, решает, сколько копий ей нужно прямо сейчас Такой вопрос — а чем хуже сразу запустить двенадцать копий? Понятно, ресурсы будут потребляться, ну и что? Оплата же не за время работы CPU в данном случае? Ведь в «кубике» после того, как cron-контейнер выполнился, ты в него больше не попадёшь. Немного похожий вопрос — чем хуже обычный контейнер, который внутри себя что-то периодически запускает? И «зайти» в него можно, и историю потребления ресурсов посмотреть. 4umak сегодня в 12:54 0 Такой вопрос — а чем хуже сразу запустить двенадцать копий? Понятно, ресурсы будут потребляться, ну и что? Оплата же не за время работы CPU в данном случае? Чтобы понимать лучше реальное потребление и, соответственно, планировать будущие мощности Немного похожий вопрос — чем хуже обычный контейнер, который внутри себя что-то периодически запускает? И «зайти» в него можно, и историю потребления ресурсов посмотреть. Собственно, всем. Для кронджобов есть отдельная инфраструктура проверок, перезапусков и прочего, в рамках самого k8s. Нет нужды залезать внутрь самого контейнера вообще. Для управления периодическими задачами в кластере сильно удобнее, чем вылавливать, где там запустился обычный контейнер, ходить в него, что-то там внутри самому проверять и пр. maxim_ge сегодня в 13:11 +2 Чтобы понимать лучше реальное потребление и, соответственно, планировать будущие мощности Честно говоря, не уловил. Вот, например, вариант 1. Запускаем сразу двенадцать копий, сразу резервируем им память, и уверены, что в случае чего, они не подведут. По телеметрии смотрим загрузку, ее динамику и так далее. Т.е. как раз понимаем реальное потребление. Теперь вариант 2. Запускаем четыре копии, на пике — двенадцать. Памяти-то хватит на пике? Непонятно. Какие конкретно преимущества имеет этот вариант по пониманию реального потребления? 4umak сегодня в 14:19 0 В первом варианте потребление ресурсов неявное. 12 запущенных контейнеров, половина из которых простаивает, потребляют ресурсов больше, чем 6 запущенных и активно работающих, но меньше, чем 12 активно работающих. Вот я о чём. И для большей точности данных мы бы предложили не плодить висящие контейнеры. maxim_ge сегодня в 15:04 0 12 запущенных контейнеров, половина из которых простаивает, потребляют ресурсов больше, чем 6 запущенных и активно работающих, но меньше, чем 12 активно работающих. Это понятно. Но сэкономленные ресурсы все равно нельзя использовать в другом месте — иначе будет трудно запустить 12 контейнеров, когда наступит время и придут миллионы читателей. К чему тогда экономия, раз она ставит по удар функционирование системы на пике нагрузки? Запустил 12 контейнеров, и все. Если остались ресурсы — можно еще что-то запустить на постоянной основе. Смысл масштабирования в рассматриваемом примере неясен. 4umak сегодня в 15:14 0 Но сэкономленные ресурсы все равно нельзя использовать в другом месте Всё так, да. В идеале подобный подход был придуман под облака, когда машины можно брать мгновенно у того же хостера за почасовую оплату. И когда у вас дикий пик х100, то вы красивый выезжаете на белом коне, заплатив чуть больше обычного месячного прайса. GKE, Heroku, вот это про них про всех. Но пока что их месячный прайс оказывается уж слишком неприятным в сравнении с покупкой железок и определённой вознёй с простаиванием/наращиванием мощностей. Поэтому пока получается такой, околопереходный период, когда сам проект инфраструктурно готов устремляться в самое отдалённое будущее, но в настоящем это стоит каких-то футуристических денег. Поэтому выбираются подобные компромиссы. Когда игроков на рынке подобных хостингов станет больше и ценники упадут до более приемлемых значений, можно будет мигрировать вообще без головной боли. maxim_ge сегодня в 15:41 +1 В идеале подобный подход был придуман под облака, когда машины можно брать мгновенно у того же хостера за почасовую оплату. Как говорилось в «Лачуге должника» — благ-за-ин! gecube сегодня в 15:47 0 Можно ссылочку на упомянутый материал? Я, видимо, что-то в этой жизни пропустил )))) maxim_ge сегодня в 16:30 0 Это Вадим Шефнер, советская фантастика. Тынц — Павел Васильевич Белобрысов,- отрекомендовался мой странный сосед.- Родился в Ленинграде в две тысячи сто седьмом году.- Произнеся это, он почему-то покосился в мою сторону.- Имею много специальностей, которые могут пригодиться где угодно. Здоровье — двенадцать баллов с гаком. — Не все понял я, уважаемый Павел Васильевич,- почтительно произнес секретарь.- Что вы имеете честь подразумевать под словом «гак»? — Гак — металлический крюк на древних кораблях, служивший для подъема грузов и шлюпок,- пояснил я элмеху. — Благ-за-ин! — поклонился мне элмех. Затем, обернувшись к Белобрысову, спросил: — Значит, могу зафиксировать и доложить Терентьеву я, что вы можете заменить собой металлический крюк и персонально осуществлять передвижение тяжелых предметов? — Да нет, это дядя шутит… Вернее, я шучу,- пробурчал Белобрысов. Там довольно много лингвистических экспериментов, на любителя, конечно, но мне нравится. maxim_ge сегодня в 12:59 0 - Только полноправные пользователи могут оставлять комментарии. Войдите, пожалуйста. Информация Дата основания 12 августа 2008 г. Локация Иркутск Россия Сайт itsumma.ru Численность 51–100 человек Дата регистрации 24 ноября 2009 г. Ссылки itsumma.ru itsumma.ru Facebook Виджет Блог на Хабре Как мы сайт Republic на Kubernetes переводили 3k 27 Нагрузочное тестирование CPU и SSD облачных хостеров: сравниваем Selectel, Servers, MCS и Я.Облако 7,2k 40 Apache Kafka и RabbitMQ: семантика и гарантия доставки сообщений 10,8k 2 Миграция с Mongo на Postgres: опыт газеты The Guardian 10,2k 37 «Надежность и безотказность как в Google» — и не только: перевод статьи «Расчёт надёжности сервиса» 5,2k 4 RabbitMQ против Kafka: применение Kafka в событийно ориентированных приложениях 15,8k 3 Проблемы обеспечения 100% доступности проекта 5k 6 RabbitMQ против Kafka: два разных подхода к обмену сообщениями 65,6k 39 Как построить IIoT архитектуру своими руками. Часть 2: «Вещи» 8,5k 14 Как построить IIoT архитектуру своими руками 9,6k 7 Самое читаемое Сутки Неделя Месяц Про удивительность пчелы, и то, как мы её убиваем +244 45,1k 205 194 Как стать Java разработчиком за 1,5 года +66 32,1k 447 85 Окей, Google! Ты добро или зло? +158 40,8k 50 188 Учёные нашли самое старое живое позвоночное на Земле +62 110k 64 182 Зарплаты в ИТ во втором полугодии 2018 года: по данным калькулятора зарплат «Моего круга» +55 35,8k 59 65 Как я год не работал в Сбербанке +403 197k 305 516 Учёные нашли самое старое живое позвоночное на Земле +62 110k 64 182 Ракета 9М729. Несколько слов о “нарушителе” Договора РСМД +35 78,4k 51 1228 Пермский программист арестован за создание мобильного приложения, через которое действовал педофил +165 73,9k 50 497 Почему Windows в 2019 году не рулит, или ЧЯДНТ? +50 66,2k 84 722 Выброшенные на помойку умные лампочки — ценный источник личной информации +62 215k 92 147 Как я год не работал в Сбербанке +403 197k 305 516 Хотите вечных светодиодов? Расчехляйте паяльники и напильники. Или домашнее освещение самодельщика +88 145k 238 261 1 февраля 2019 года ваш сайт может перестать работать +81 141k 154 162 Про одного парня +207 112k 655 244 Аккаунт Войти Регистрация Разделы Публикации Хабы Компании Пользователи Песочница Информация Правила Помощь Документация Соглашение Конфиденциальность Услуги Реклама Тарифы Контент Семинары Приложения © 2006 – 2019 «TM» Настройка языка О сайте Служба поддержки Мобильная версия Настройка языка Интерфейс Русский English Язык публикаций Русский English Сохранить настройки