Хабр Geektimes Тостер Мой круг Фрилансим Мегапосты: Публикации Пользователи Хабы Компании Песочница Войти Регистрация alizar вчера в 19:40 Серьёзные математические ошибки NHTSA позволили Tesla заявить о безопасности автопилота Статистика в IT Национальная администрация безопасности дорожного движения (NHTSA) крупно рискует своей репутацией после разгромного отчёта, который опубликовала маленькая исследовательская и консалтинговая фирма под названием Quality Control Systems. Этот отчёт посвящён анализу доклада NHTSA от 2017 года, в результате которого чиновники выяснили, что автопилот Tesla снижает риск попасть в ДТП на 40% (диаграмма выше). Отчёт опубликован только сейчас, почти через два года. Quality Control Systems пришлось подать в суд на NHTSA, чтобы в соответствии с законом «О свободе информации» получить данные, лежащие в основе выводов агентства. В своём докладе QCS говорит о недостатках методологии NHTSA, которые достаточно серьёзны, чтобы полностью дискредитировать 40-процентную цифру, которую Tesla несколько раз цитировала за последние два года, подчёркивая пользу автопилота для безопасности. NHTSA изучила безопасность автопилота после аварии со смертельным исходом владельца Tesla Джошуа Брауна в 2016 году. Автопилот, а точнее функция поддержания полосы Autosteer, была активна во время аварии, и Браун проигнорировал несколько предупреждений, чтобы положить руки обратно на рулевое колесо. Критики задались вопросом, может автопилот снижает безопасность, стимулируя водителя меньше внимания уделять дороге? Однако NHTSA выяснила, что на самом деле Autosteer снизил аварийность на 40%, так что всё в порядке. Tesla цитировала эту цифру в своём блоге, где приводила аргументы в защиту технологии. Через несколько недель Илон Маск даже ругал репортёров, которые «зациклились» на авариях Tesla, а не рассказывают о том, что автопилот объективно делает вождение более безопасным. Как выясняется, доводы Илона Маска могли возникнуть в результате фатальной ошибки экспертов Tesla в подсчёте статистики. В чём суть, если вкратце. Как NHTSA оценивала безопасность транспорта? Самым понятным и логичным способом. Они запросили у Tesla полную статистику по всем автомобилям, проданным между 2014 и 2016 годами, и посчитали коэффициент аварийности до и после установки Autosteer. Методику выбрали такую: взяли количество аварий до установки автопилота и поделили на количество пройденных миль до активации Autosteer. Аналогично, взяли количество аварий после установки автопилота и тоже поделили на количество пройденных миль после активации Autosteer. Всего Tesla предоставила данные по 43 781 автомобилю. Проблема только в том, что в таблице от Tesla по большинству автомобилей данные неполные. Например, не указано, в какой момент на автомобиле был активирован Autosteer. Оказалось, что по 29 051 автомобилю в базе отсутствуют необходимые поля для проведения таких вычислений. NHTSA при подсчёте посчитала все эти автомобили как на 100% оснащённые Autosteer, словно они ни одной мили не проехали перед активацией этой функции. Однако 18 ДТП, которые произошли с участием этих автомобилей, занесены в статистику до Autosteer, а это более 20% из всех 86 аварий, которые произошли с автомобилями Tesla без функции Autosteer! Совершенно очевидно, что такой серьёзный перекос в подсчёте итоговой статистики сильно сдвинул результат в пользу безопасности Autosteer. Насколько сильно — неизвестно. Мы не можем посчитать реальные данные по всей выборке, поскольку бóльшая часть данных повреждена. Однако QCS провела аналогичные вычисления для 5714 автомобилей, по которым была полная информация одометра «до Autosteer» и «после Autosteer» без зазора между этими двумя пунктами (это ещё один недостаток базы Tesla: во многих автомобилях эти две цифры не совпадали). Так вот, на нормальной выборке подсчёт показал, что аварийность после установки Autosteer увеличилась на 59%. Хотя и это нельзя считать объективной цифрой, потому что 5714 машин представляют слишком малую часть автопарка Tesla и нет способа понять, являются ли они репрезентативной выборкой. Судя по всему, NHTSA давно заметила свою ошибку, просто стеснялась в ней признаться. Ещё в мае прошлого года ведомство дистанцировалось от собственного отчёта, назвав его «беглым сравнением», которое «не оценивает эффективность технологии Autosteer». Почему они так долго отказывались передать QCS исходные данные для повторной экспертизы? Ведь запрос на информацию был отослан в феврале 2017 года, примерно через месяц после публикации оригинального отчёта. Агентство не могло сразу выдать информацию потому, что компания Tesla заявила о конфиденциальности данных. Только в ходе судебного разбирательства суд отверг аргументы NHTSA о конфиденциальности статистики и приказал рассекретить информацию. Теги: статистика Tesla автопилот NHTSA Добавить метки Пометьте публикацию своими метками Метки лучше разделять запятой. Например: программирование, алгоритмы Сохранить Объявляем конкурс статей от РТЛабс и Хабра Принять участие Читают сейчас Сказ о сплаве Розе и отвалившейся КРЕНке 36,3k 60 Состоялся релиз Kali Linux 2019.1 6,4k 11 Подборка: 4 полезных сервиса для потенциальных иммигрантов в США, Европу и другие страны 9,4k 1 Андрей Гейм: Бойтесь технологического кризиса 9,2k 47 Серьёзные математические ошибки NHTSA позволили Tesla заявить о безопасности автопилота 9,5k 23 — А вы там в нефтехимии бензин делаете, да? 16,4k 115 +25 13 9,5k 23 Выберите рекомендации для отправки автору: Указан только блог Орфографические ошибки Пунктуационные ошибки Отступы Текст-простыня Короткие предложения Смайлики Много форматирования Картинки Ссылки Оформление кода Рекламный характер Отправить Нарушение Опишите суть нарушения Отправить 837,5 Карма 1667,7 Рейтинг 1342 Подписчики Анатолий Ализар alizar Редактор Поделиться публикацией Похожие публикации 27 октября 2015 в 22:17 Автопилот Tesla проверили на московских дорогах +17 23,4k 29 52 22 октября 2015 в 20:25 Владельцы Tesla игнорируют рекомендации безопасности и опускают руки с руля +23 20,1k 12 48 15 октября 2015 в 10:30 Видео движения Tesla в режиме автопилота в городских условиях +27 19,3k 12 67 Заказы Разработка сайта: статистика и визуализация данных 19 откликов 137 просмотров 100000 за проект Решить задачу по статистике 3 отклика 99 просмотров 2000 за проект Написание статьи на тематику "Практика в Канаде" 5 откликов 46 просмотров 9000 за проект Требуется технический переводчик на проект 19 откликов 77 просмотров 5000 за месяц Создание воронки в месенджере 5 откликов 34 просмотра 50000 за проект Все заказы Разместить заказ Комментарии 23 TimsTims вчера в 21:09 +2 Ну вот и еще одним скандалом попахивает. Прямо как скандал с выхлопными газами: все производители автомобилей врут, даже Тесла. Пророчу уровень 2: Тесла начинает предоставлять ограниченную статистику и только по самому безопасному региону, где приятней всего статистика. Уровень 3: Тесла нагло манипулирует данными, подменяя одно на другое. striver вчера в 21:24 0 Уровень 0: выдаем отчет по безопасности ежеквартально. mk2 вчера в 21:54 0 Уровень -1: и в этом отчете найдут ошибки striver вчера в 21:55 0 Ну, они подписывают эти данные, с ними можно идти в суд… и откусить не слабый кусок черной икры. mk2 вчера в 22:06 +2 Сначала надо у Теслы получить сырые данные, на основе которых они делают свой отчёт. А с этим будут проблемы, у них нет никакой обязанности их давать. BlackMokona вчера в 23:21 0 Так пусть запросит для начала Dee3 сегодня в 01:18 0 Финансовые аналитики пророчат уровень «дно» — из компании в последний год ушло много топов, особенно связанных с финансами. Если в этом году компания выживет — возможно и ваше пророчество сбудется ggreminder вчера в 22:32 0 Всё так и есть, только манипуляции это не отменяет. Я очень радею за подвижки в этой области, только не нужно выдавать желаемое за действительное. Тесла в поквартальном отчёте не раскрывает аварийность по компонентам, а выше речь шла только про Autosteer (а не про весь «автопилот»). striver вчера в 22:45 –3 Ну, каждый находит нужные ему данные. lingvo вчера в 23:06 0 А в обсуждаемом отчете NHTSA вообще шла речь о airbag deployment crash rate. О чем тут можно судить? Lissov сегодня в 02:42 +1 Если я правильно понимаю английский, то речь идёт о критерии что называть аварией. С точки зрения «безопасности автопилота» звучит логично. Во-первых, нас не интересуют аварии вида «зацепил столбик на парковке» или «поцарапал ключом дверь». Во-вторых, срабатывание подушки однозначно видно по телеметрии. Igor_Shumilov сегодня в 00:46 +2 «Есть ложь, наглая ложь и статистика» (с) Марк Твен А анализировались ли последствия аварий на автопилоте и без него? Человеческие ошибки приводят к ДТП вида «отпустил педаль тормоза на светофоре и притёр машину спереди». А ошибка автопилота может привести к «не распознал кузов грузовика как препятствие и проехал сквозь него не снижая скорости». Первых аварий может быть сто, а вторых пять на одинаковый пробег. Но фактически безопасней будут первые. Ogra сегодня в 05:11 0 Рассматриваются только аварии, при которых сработала подушка безопасности. На мой взгляд, достаточно неплохой критерий для оценки именно безопасности. KonkovVladimir сегодня в 05:41 0 А на мой взгляд — лучшим критерием является «Средний километраж до ДТП со смертельным исходом» для США это примерно 150 млн км. График Статистика по 86 авариям без Autosteer это конечно внушаитъ! Да и кстати, где error bars на графике? P.S. И еще, никто не мешает сравнить статистику срабатывания подушек на Tesla с таковой для других автомобилей — то-есть ответить на вопрос «является ли Tesla с частично включеным Autosteer, безопаснее чем среднестатистический автомобиль» Ogra сегодня в 06:11 0 Ну блин, вы уж определитесь, что вы хотите — большую выборку, или лучший критерий. Потому что сейчас по Теслам получить и то и то ну никак не представляется возможным. KonkovVladimir сегодня в 07:18 0 Да любую выборку — главное error bars нарисуйте, подтверждение 0-й гипотезы тоже является значимым результатом. samodum сегодня в 02:18 0 del TrueMaker сегодня в 06:51 0 Не знаю как статистика у них работает, но Tesla с Autopilot 2.5 меня уже 2 раза спасала от аварий. Первый раз было резкое аварийное торможение и машина остановилась не врезавшись в машину впереди раньше, чем я вообще понял, что произошло. Второй раз, какой-то чудный водитель пикапа пытался перестроится в мою полосу, Тесла резко выехала на обочину резко сбросив скорость, на этом этапе я уже перехватил управление и вернулся назад на полосу. grondek сегодня в 07:56 0 >> Первый раз было резкое аварийное торможение и машина остановилась не врезавшись в машину впереди раньше, чем я вообще понял, что произошло Надо держать дистанцию и не щелкать клювом — это лично ваш косяк. >> Тесла резко выехала на обочину резко сбросив скорость А вот так делать нельзя, последствия могли быть намного хуже, чем если бы вы впечатались в зад пикапа. TrueMaker сегодня в 08:04 0 Согласен с первым, мой косяк в некотором смысле, но был спасён. И машина которая остановилась впереди меня остановилась об другую машину практически мгновенно, не знаю какую дистанцию я должен был держать. Во втором случае не согласен, эта обочина используется для аварийных остановок в обычном случае. Там нормальное асфальтированное покрытие и вполне можно остановится если что-то случится. grondek сегодня в 09:05 0 Дистанция грубо половина скорости в метрах + немного. Это на хорошем асфальте летом. Все равно, чтобы уходить от столкновения надо четко понимать, что там куда ты уходишь все хорошо, нет помех, и покрытие однородное. Если tesla видела ситуацию на обочине — отлично, если тупо отворачивала от опасности, то поведение надо дорабатывать. staticlab сегодня в 08:12 0 Не знаю как статистика у них работает, но Tesla с Autopilot 2.5 меня уже 2 раза спасала от аварий. Первый раз было резкое аварийное торможение и машина остановилась не врезавшись в машину впереди раньше, чем я вообще понял, что произошло. Так это давно умеют и машины без автопилота, например, Volvo. TrueMaker сегодня в 08:26 0 Аварийное торможение много кто умеет, а вот уходить от столкновения… Только полноправные пользователи могут оставлять комментарии. Войдите, пожалуйста. Что обсуждают Сейчас Вчера Неделя Методы рационального мышления и Магрибский молитвенный коврик 14,9k 102 Отзывы о работодателях: природа и бессмысленность анонимных отзывов 5,1k 42 Вариант клонирования БД для разработки/тестирования 1,2k 4 Андрей Гейм: Бойтесь технологического кризиса 9,2k 47 Электромобили утянут на дно автокорпорации? 19,8k 207 — А вы там в нефтехимии бензин делаете, да? 16,4k 115 Методы рационального мышления и Магрибский молитвенный коврик 14,9k 102 Сказ о сплаве Розе и отвалившейся КРЕНке 36,3k 60 NASA покупает еще два места на «Союзах», испытывает RS-25 и не отказывается от околоземной станции 12,1k 60 Андрей Гейм: Бойтесь технологического кризиса 9,2k 47 10 млрд. экспорта ПО – это ничтожно мало 12,6k 416 Законопроект об «устойчивой работе» Рунета — что делать до второго чтения? 45,1k 373 Безумие дотфайлов 37,9k 255 InterNyet — как в Советском Союзе изобрели интернет и почему он не заработал 63,3k 241 Разработчик SearchFace о возможностях алгоритма 49,3k 239 Самое читаемое Сутки Неделя Месяц Сказ о сплаве Розе и отвалившейся КРЕНке +115 36,3k 77 60 Безумие дотфайлов +147 37,9k 190 255 Что не так с Raspberry Pi +103 62,6k 246 128 — А вы там в нефтехимии бензин делаете, да? +87 16,4k 63 115 Корпоративный туалет +8 20,8k 29 68 Увеличь это! Современное увеличение разрешения +351 97,9k 364 209 Яндекс! Спасибо за Uber +142 63,5k 37 235 InterNyet — как в Советском Союзе изобрели интернет и почему он не заработал +82 63,3k 175 241 Что не так с Raspberry Pi +103 62,6k 246 128 Собеседуем работодателя или как не уволиться в первый месяц +100 59k 270 162 Как я год не работал в Сбербанке +421 225k 329 577 Выброшенные на помойку умные лампочки — ценный источник личной информации +62 218k 92 147 Учёные нашли самое старое живое позвоночное на Земле +68 203k 71 211 Хотите вечных светодиодов? Расчехляйте паяльники и напильники. Или домашнее освещение самодельщика +88 148k 246 262 Про одного парня +206 118k 675 245 Хабр рекомендует Разместить Несколько интересных кейсов с SAP HANA: потенциал big data и машинного обучения Криптонит для мозга: IT-ребус от Криптонит Startup Challenge Аккаунт Войти Регистрация Разделы Публикации Хабы Компании Пользователи Песочница Информация Правила Помощь Документация Соглашение Конфиденциальность Услуги Реклама Тарифы Контент Семинары Приложения © 2006 – 2019 «TM» Настройка языка О сайте Служба поддержки Мобильная версия Настройка языка Интерфейс Русский English Язык публикаций Русский English Сохранить настройки